{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_in_Finance_QLBS_Option_Pricing\n",
    "# Author: Igor Halperin\n",
    "# Version: 1.0 (06.05.2020)\n",
    "# License: MIT\n",
    "# Email: matthew.dixon@iit.edu\n",
    "# Notes: tested on Mac OS X with Python 3.6.9 and the following packages:\n",
    "# matplotlib=3.1.3, numpy=1.18.1, scipy=1.4.1, pandas=1.0.4\n",
    "# Citation: Please cite the following reference if this notebook is used for research purposes:\n",
    "# Bilokon P., Dixon M.F. and Halperin I., Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for MC simulation of stock prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by simulating stock price dynamics under GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 100      # initial stock price\n",
    "mu = 0.05     # drift\n",
    "sigma = 0.15  # volatility\n",
    "r = 0.03      # risk-free rate\n",
    "\n",
    "M = 1         # maturity\n",
    "T = 24        # number of time steps\n",
    "\n",
    "N_MC = 1000    # number of paths\n",
    "\n",
    "delta_t = M / T                # time interval\n",
    "gamma = np.exp(- r * delta_t)  # discount factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM Simulation\n",
    "Simulate $N_{MC}$ stock price sample paths with $T$ steps by the classical GBM formula.\n",
    "\n",
    "$$dS_t=\\mu S_tdt+\\sigma S_tdW_t\\quad\\quad S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n",
    "\n",
    "where $Z$ is a standard normal random variable.\n",
    "\n",
    "Based on simulated stock price $S_t$ paths, compute state variable $X_t$ by the following relation.\n",
    "\n",
    "$$X_t=-\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)t\\Delta t+\\log S_t$$\n",
    "\n",
    "Also compute\n",
    "\n",
    "$$\\Delta S_t=S_{t+1}-e^{r\\Delta t}S_t\\quad\\quad \\Delta\\hat{S}_t=\\Delta S_t-\\Delta\\bar{S}_t\\quad\\quad t=0,...,T-1$$\n",
    "\n",
    "where $\\Delta\\bar{S}_t$ is the sample mean of all values of $\\Delta S_t$.\n",
    "\n",
    "Plots of 5 stock price $S_t$ and state variable $X_t$ paths are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make two datasets \n",
    "# the second dataset will be needed below for Double Q-Learning\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# stock price\n",
    "S = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "S.loc[:,0] = S0\n",
    "\n",
    "S_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "S_1.loc[:,0] = S0\n",
    "\n",
    "# standard normal random numbers\n",
    "RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))\n",
    "RN_1 = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))\n",
    "\n",
    "for t in range(1, T+1):\n",
    "    S.loc[:,t] = S.loc[:,t-1] * np.exp((mu - 1/2 * sigma**2) * delta_t + sigma * np.sqrt(delta_t) * RN.loc[:,t])\n",
    "    S_1.loc[:,t] = S_1.loc[:,t-1] * np.exp((mu - 1/2 * sigma**2) * delta_t + sigma * np.sqrt(delta_t) * RN_1.loc[:,t])\n",
    "\n",
    "delta_S = S.loc[:,1:T].values - np.exp(r * delta_t) * S.loc[:,0:T-1]\n",
    "delta_S_hat = delta_S.apply(lambda x: x - np.mean(x), axis=0)\n",
    "\n",
    "delta_S_1 = S_1.loc[:,1:T].values - np.exp(r * delta_t) * S_1.loc[:,0:T-1]\n",
    "delta_S_hat_1 = delta_S_1.apply(lambda x: x - np.mean(x), axis=0)\n",
    "\n",
    "# state variable\n",
    "X = - (mu - 1/2 * sigma**2) * np.arange(T+1) * delta_t + np.log(S)   # delta_t here is due to their conventions\n",
    "X_1 = - (mu - 1/2 * sigma**2) * np.arange(T+1) * delta_t + np.log(S_1) \n",
    "\n",
    "endtime = time.time()\n",
    "print('\\nTime Cost:', endtime - starttime, 'seconds')\n",
    "\n",
    "# plot 10 paths\n",
    "step_size = N_MC // 10\n",
    "idx_plot = np.arange(step_size, N_MC, step_size)\n",
    "plt.plot(S.T.iloc[:, idx_plot])\n",
    "plt.xlabel('Time Steps')\n",
    "plt.title('Stock Price Sample Paths')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X.T.iloc[:, idx_plot])\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('State Variable');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function *terminal_payoff* to compute the terminal payoff of a European put option.\n",
    "\n",
    "$$H_T\\left(S_T\\right)=\\max\\left(K-S_T,0\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal_payoff(ST, K):\n",
    "    # ST   final stock price\n",
    "    # K    strike\n",
    "    payoff = max(K - ST, 0)\n",
    "    return payoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define spline basis functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bspline\n",
    "import bspline.splinelab as splinelab\n",
    "\n",
    "X_min = np.min(np.min(X))\n",
    "X_max = np.max(np.max(X))\n",
    "\n",
    "print('X.shape = ', X.shape)\n",
    "print('X_min, X_max = ', X_min, X_max)\n",
    "\n",
    "p = 4 # order of spline (as-is; 3: cubic, 4: B-spline?)\n",
    "ncolloc = 12\n",
    "\n",
    "tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n",
    "\n",
    "# k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n",
    "# To get meaninful results, one should have ncolloc >= p+1\n",
    "k = splinelab.aptknt(tau, p) \n",
    "                             \n",
    "# Spline basis of order p on knots k\n",
    "basis = bspline.Bspline(k, p)        \n",
    "f = plt.figure()\n",
    "\n",
    "print('Number of points k = ', len(k))\n",
    "basis.plot()\n",
    "\n",
    "plt.savefig('Basis_functions.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data matrices with feature values\n",
    "\n",
    "\"Features\" here are the values of basis functions at data points\n",
    "The outputs are 3D arrays of dimensions num_tSteps x num_MC x num_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_t_steps = T + 1\n",
    "num_basis =  ncolloc \n",
    "\n",
    "data_mat_t = np.zeros((num_t_steps, N_MC,num_basis ))\n",
    "data_mat_t_1 = np.zeros((num_t_steps, N_MC,num_basis ))\n",
    "\n",
    "print('num_basis = ', num_basis)\n",
    "print('dim data_mat_t = ', data_mat_t.shape)\n",
    "\n",
    "t_0 = time.time()\n",
    "\n",
    "# fill it \n",
    "for i in np.arange(num_t_steps):\n",
    "    x = X.values[:,i]\n",
    "    x_1 = X_1.values[:,i]\n",
    "    data_mat_t[i,:,:] = np.array([ basis(i) for i in x ])\n",
    "    data_mat_t_1[i,:,:] = np.array([ basis(i) for i in x_1 ])\n",
    "    \n",
    "t_end = time.time()\n",
    "print('Computational time:', t_end - t_0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these data matrices for future re-use\n",
    "np.save('data_mat_m=r_A_%d' % N_MC, data_mat_t)\n",
    "np.save('data_mat_m=r_B_%d' % N_MC, data_mat_t_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_mat_t.shape) # shape: num_steps x N_MC x num_basis\n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming solution for QLBS \n",
    "\n",
    "The MDP problem in this case is to solve the following Bellman optimality equation for the action-value function.\n",
    "\n",
    "$$Q_t^\\star\\left(x,a\\right)=\\mathbb{E}_t\\left[R_t\\left(X_t,a_t,X_{t+1}\\right)+\\gamma\\max_{a_{t+1}\\in\\mathcal{A}}Q_{t+1}^\\star\\left(X_{t+1},a_{t+1}\\right)\\space|\\space X_t=x,a_t=a\\right],\\space\\space t=0,...,T-1,\\quad\\gamma=e^{-r\\Delta t}$$\n",
    "\n",
    "where $R_t\\left(X_t,a_t,X_{t+1}\\right)$ is the one-step time-dependent random reward and $a_t\\left(X_t\\right)$ is the action (hedge).\n",
    "\n",
    "Detailed steps of solving this equation by Dynamic Programming are illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this set of basis functions $\\left\\{\\Phi_n\\left(X_t^k\\right)\\right\\}_{n=1}^N$, expand the optimal action (hedge) $a_t^\\star\\left(X_t\\right)$ and optimal Q-function $Q_t^\\star\\left(X_t,a_t^\\star\\right)$ in basis functions with time-dependent coefficients.\n",
    "$$a_t^\\star\\left(X_t\\right)=\\sum_n^N{\\phi_{nt}\\Phi_n\\left(X_t\\right)}\\quad\\quad Q_t^\\star\\left(X_t,a_t^\\star\\right)=\\sum_n^N{\\omega_{nt}\\Phi_n\\left(X_t\\right)}$$\n",
    "\n",
    "Coefficients $\\phi_{nt}$ and $\\omega_{nt}$ are computed recursively backward in time for $t=Tâˆ’1,...,0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients for expansions of the optimal action $a_t^\\star\\left(X_t\\right)$ are solved by\n",
    "\n",
    "$$\\phi_t=\\mathbf A_t^{-1}\\mathbf B_t$$\n",
    "\n",
    "where $\\mathbf A_t$ and $\\mathbf B_t$ are matrix and vector respectively with elements given by\n",
    "\n",
    "$$A_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\Phi_m\\left(X_t^k\\right)\\left(\\Delta\\hat{S}_t^k\\right)^2}\\quad\\quad B_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\left[\\hat\\Pi_{t+1}^k\\Delta\\hat{S}_t^k+\\frac{1}{2\\gamma\\lambda}\\Delta S_t^k\\right]}$$\n",
    "\n",
    "Define function *function_A* and *function_B* to compute the value of matrix $\\mathbf A_t$ and vector $\\mathbf B_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the option strike and risk aversion parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_lambda = 0.001 # risk aversion parameter\n",
    "\n",
    "K = 100 # strike  \n",
    "\n",
    "# Note that we set coef=0 below in function function_B_vec. This corresponds to a pure risk-based hedging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to compute optimal hedges\n",
    "def function_A_vec(t,delta_S_hat,data_mat,reg_param):\n",
    "    # Compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
    "    X_mat = data_mat_t[t,:,:]\n",
    "    num_basis_funcs = X_mat.shape[1]\n",
    "    this_dS = delta_S_hat.loc[:,t].values\n",
    "    hat_dS2 = (this_dS**2).reshape(-1,1)    \n",
    "    A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n",
    "    return A_mat\n",
    "        \n",
    "def function_B_vec(t, Pi_hat, delta_S=delta_S, delta_S_hat=delta_S_hat, S=S, data_mat=data_mat_t,\n",
    "                  gamma=gamma,risk_lambda=risk_lambda):\n",
    "    # coef = 1.0/(2 * gamma * risk_lambda)\n",
    "    # override it by zero to have pure risk hedge\n",
    "    coef = 0\n",
    "    tmp =  Pi_hat.loc[:,t+1] * delta_S_hat.loc[:,t] + coef * (np.exp(mu*delta_t) - np.exp(r*delta_t))* S.loc[:,t]\n",
    "    X_mat = data_mat_t[t,:,:]  # matrix of dimension N_MC x num_basis\n",
    "    \n",
    "    B = np.dot(X_mat.T, tmp)    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute optimal hedge and portfolio value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call *function_A* and *function_B* for $t=T-1,...,0$ together with basis function $\\Phi_n\\left(X_t\\right)$ to compute optimal action $a_t^\\star\\left(X_t\\right)=\\sum_n^N{\\phi_{nt}\\Phi_n\\left(X_t\\right)}$ backward recursively with terminal condition $a_T^\\star\\left(X_T\\right)=0$.\n",
    "\n",
    "Once the optimal hedge $a_t^\\star\\left(X_t\\right)$ is computed, the portfolio value $\\Pi_t$ could also be computed backward recursively by \n",
    "\n",
    "$$\\Pi_t=\\gamma\\left[\\Pi_{t+1}-a_t^\\star\\Delta S_t\\right]\\quad t=T-1,...,0$$\n",
    "\n",
    "together with the terminal condition $\\Pi_T=H_T\\left(S_T\\right)=\\max\\left(K-S_T,0\\right)$ for a European put option.\n",
    "\n",
    "Also compute $\\hat{\\Pi}_t=\\Pi_t-\\bar{\\Pi}_t$, where $\\bar{\\Pi}_t$ is the sample mean of all values of $\\Pi_t$.\n",
    "\n",
    "Plots of 5 optimal hedge $a_t^\\star$ and portfolio value $\\Pi_t$ paths are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "# portfolio value\n",
    "Pi = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi.iloc[:,-1] = S.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
    "\n",
    "Pi_hat = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_hat.iloc[:,-1] = Pi.iloc[:,-1] - np.mean(Pi.iloc[:,-1])\n",
    "\n",
    "# optimal hedge\n",
    "a = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a.iloc[:,-1] = 0\n",
    "\n",
    "# twin variables for the second dataset\n",
    "# portfolio value\n",
    "Pi_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_1.iloc[:,-1] = S_1.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
    "\n",
    "Pi_hat_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_hat_1.iloc[:,-1] = Pi_1.iloc[:,-1] - np.mean(Pi_1.iloc[:,-1])\n",
    "\n",
    "# optimal hedge\n",
    "a_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a_1.iloc[:,-1] = 0\n",
    "\n",
    "reg_param = 1e-3\n",
    "\n",
    "for t in range(T-1, -1, -1):\n",
    "    A_mat = function_A_vec(t, delta_S_hat, data_mat_t, reg_param)\n",
    "    B_vec = function_B_vec(t, Pi_hat)\n",
    "\n",
    "    # print ('t =  A_mat.shape = B_vec.shape = ', t, A_mat.shape, B_vec.shape)\n",
    "    phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "\n",
    "    a.loc[:,t] = np.dot(data_mat_t[t,:,:],phi)\n",
    "    Pi.loc[:,t] = gamma * (Pi.loc[:,t+1] - a.loc[:,t] * delta_S.loc[:,t])\n",
    "    Pi_hat.loc[:,t] = Pi.loc[:,t] - np.mean(Pi.loc[:,t])\n",
    "\n",
    "    # and the same for the twin dataset:\n",
    "    A_mat_1 = function_A_vec(t,delta_S_hat_1,data_mat_t_1,reg_param)\n",
    "    B_vec_1 = function_B_vec(t, Pi_hat_1)\n",
    "    phi_1 = np.dot(np.linalg.inv(A_mat_1), B_vec_1)\n",
    "    a_1.loc[:,t] = np.dot(data_mat_t_1[t,:,:],phi_1)\n",
    "    Pi_1.loc[:,t] = gamma * (Pi_1.loc[:,t+1] - a_1.loc[:,t] * delta_S_1.loc[:,t])\n",
    "    Pi_hat_1.loc[:,t] = Pi_1.loc[:,t] - np.mean(Pi_1.loc[:,t])\n",
    "\n",
    "a = a.astype('float')\n",
    "Pi = Pi.astype('float')\n",
    "Pi_hat = Pi_hat.astype('float')\n",
    "\n",
    "a_1 = a_1.astype('float')\n",
    "Pi_1 = Pi_1.astype('float')\n",
    "Pi_hat_1 = Pi_hat_1.astype('float')\n",
    "\n",
    "endtime = time.time()\n",
    "print('Computational time:', endtime - starttime, 'seconds')\n",
    "\n",
    "# plot 10 paths\n",
    "plt.plot(a.T.iloc[:,idx_plot])\n",
    "plt.xlabel('Time Steps')\n",
    "plt.title('Optimal Hedge')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Pi.T.iloc[:,idx_plot])\n",
    "plt.xlabel('Time Steps')\n",
    "plt.title('Portfolio Value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the optimal hedge $a_t^\\star$ and portfolio value $\\Pi_t$ are all computed, the reward function $R_t\\left(X_t,a_t,X_{t+1}\\right)$ could then be computed by\n",
    "\n",
    "$$R_t\\left(X_t,a_t,X_{t+1}\\right)=\\gamma a_t\\Delta S_t-\\lambda Var\\left[\\Pi_t\\space|\\space\\mathcal F_t\\right]\\quad t=0,...,T-1$$\n",
    "\n",
    "with terminal condition $R_T=-\\lambda Var\\left[\\Pi_T\\right]$.\n",
    "\n",
    "Plot of 5 reward function $R_t$ paths is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the optimal Q-function with the DP approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients for expansions of the optimal Q-function $Q_t^\\star\\left(X_t,a_t^\\star\\right)$ are solved by\n",
    "\n",
    "$$\\omega_t=\\mathbf C_t^{-1}\\mathbf D_t$$\n",
    "\n",
    "where $\\mathbf C_t$ and $\\mathbf D_t$ are matrix and vector respectively with elements given by\n",
    "\n",
    "$$C_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\Phi_m\\left(X_t^k\\right)}\\quad\\quad D_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\left(R_t\\left(X_t,a_t^\\star,X_{t+1}\\right)+\\gamma\\max_{a_{t+1}\\in\\mathcal{A}}Q_{t+1}^\\star\\left(X_{t+1},a_{t+1}\\right)\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function *function_C* and *function_D* to compute the value of matrix $\\mathbf C_t$ and vector $\\mathbf D_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_C_vec(t,data_mat_t,reg_param):\n",
    "    # Compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
    "    X_mat = data_mat_t[t,:,:]\n",
    "    num_basis_funcs = X_mat.shape[1]    \n",
    "    C_mat = np.dot(X_mat.T, X_mat) + reg_param * np.eye(num_basis_funcs)\n",
    "    return C_mat\n",
    "\n",
    "def function_D_vec(t, Q, R, data_mat_t, gamma=gamma):\n",
    "    X_mat = data_mat_t[t,:,:]\n",
    "    tmp = R.loc[:,t] + gamma * Q.loc[:,t+1]  # note that the second argument in Q is t+1 !\n",
    "    D = np.dot(X_mat.T, tmp.values)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call *function_C* and *function_D* for $t=T-1,...,0$ together with basis function $\\Phi_n\\left(X_t\\right)$ to compute optimal action Q-function $Q_t^\\star\\left(X_t,a_t^\\star\\right)=\\sum_n^N{\\omega_{nt}\\Phi_n\\left(X_t\\right)}$ backward recursively with terminal condition $Q_T^\\star\\left(X_T,a_T=0\\right)=-\\Pi_T\\left(X_T\\right)-\\lambda Var\\left[\\Pi_T\\left(X_T\\right)\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the QLBS price to European put price given by Black-Sholes formula.\n",
    "\n",
    "$$C_t^{\\left(BS\\right)}=Ke^{-r\\left(T-t\\right)}\\mathcal N\\left(-d_2\\right)-S_t\\mathcal N\\left(-d_1\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Black-Scholes prices\n",
    "def bs_put(t, S0=S0, K=K, r=r, sigma=sigma, T=M):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S0 * norm.cdf(-d1)\n",
    "    return price\n",
    "\n",
    "def bs_call(t, S0=S0, K=K, r=r, sigma=sigma, T=M):\n",
    "    d1 = (np.log(S0/K) + (r + 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    d2 = (np.log(S0/K) + (r - 1/2 * sigma**2) * (T-t)) / sigma / np.sqrt(T-t)\n",
    "    price = S0 * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)\n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hedging and Pricing with Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a batch-mode off-policy model-free Q-Learning by Fitted Q-Iteration. The only data available is given by a set of $N_{MC}$ paths for the underlying state variable $X_t$, hedge position $a_t$, instantaneous reward $R_t$ and the next-time value $X_{t+1}$.\n",
    "\n",
    "$$\\mathcal F_t^k=\\left\\{\\left(X_t^k,a_t^k,R_t^k,X_{t+1}^k\\right)\\right\\}_{t=0}^{T-1}\\quad k=1,...,N_{MC}$$\n",
    "\n",
    "Detailed steps of solving the Bellman optimalty equation by Reinforcement Learning are illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand Q-function in basis functions with time-dependent coefficients parametrized by a matrix $\\mathbf W_t$.\n",
    "\n",
    "$$Q_t^\\star\\left(X_t,a_t\\right)=\\mathbf A_t^T\\mathbf W_t\\Phi\\left(X_t\\right)=\\mathbf A_t^T\\mathbf U_W\\left(t,X_t\\right)=\\vec{W}_t^T \\vec{\\Psi}\\left(X_t,a_t\\right)$$\n",
    "\n",
    "$$\\mathbf A_t=\\left(\\begin{matrix}1\\\\a_t\\\\\\frac{1}{2}a_t^2\\end{matrix}\\right)\\quad\\mathbf U_W\\left(t,X_t\\right)=\\mathbf W_t\\Phi\\left(X_t\\right)$$\n",
    "\n",
    "where $\\vec{W}_t$ is obtained by concatenating columns of matrix $\\mathbf W_t$ while \n",
    "$ vec \\left( {\\bf \\Psi} \\left(X_t,a_t \\right) \\right) = \n",
    "  vec \\, \\left( {\\bf A}_t  \\otimes {\\bf \\Phi}^T(X) \\right) $ stands for \n",
    "a vector obtained by concatenating columns of the outer product of vectors $ {\\bf A}_t $ and $ {\\bf \\Phi}(X) $.\n",
    "\n",
    "Compute vector $\\mathbf A_t$ then compute $\\vec\\Psi\\left(X_t,a_t\\right)$ for each $X_t^k$ and store in a dictionary with key path and time $\\left[k,t\\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of DP solution\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make off-policy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disturbance level eta: Each action is multiplied by a uniform r.v. in the interval [1-eta, 1 + eta]\n",
    "eta = 0.1\n",
    "reg_param = 1e-3\n",
    "\n",
    "a_op = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a_op.iloc[:,-1] = 0\n",
    "\n",
    "a_op_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a_op_1.iloc[:,-1] = 0\n",
    "\n",
    "# also make portfolios and rewards\n",
    "# portfolio value\n",
    "Pi_op = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_op.iloc[:,-1] = S.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
    "\n",
    "Pi_op_hat = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_op_hat.iloc[:,-1] = Pi_op.iloc[:,-1] - np.mean(Pi_op.iloc[:,-1])\n",
    "\n",
    "Pi_op_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_op_1.iloc[:,-1] = S_1.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
    "\n",
    "Pi_op_hat_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Pi_op_hat_1.iloc[:,-1] = Pi_op_1.iloc[:,-1] - np.mean(Pi_op_1.iloc[:,-1])\n",
    "\n",
    "# reward function\n",
    "R_op = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "R_op.iloc[:,-1] = - risk_lambda * np.var(Pi_op.iloc[:,-1])\n",
    "\n",
    "R_op_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "R_op_1.iloc[:,-1] = - risk_lambda * np.var(Pi_op_1.iloc[:,-1])\n",
    "\n",
    "# The backward loop\n",
    "for t in range(T-1, -1, -1):\n",
    "    # 1. Compute the optimal policy, and write the result to a_op\n",
    "    A_mat = function_A_vec(t, delta_S_hat, data_mat_t, reg_param)\n",
    "    B_vec = function_B_vec(t, Pi_hat)\n",
    "    phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "    \n",
    "    A_mat_1 = function_A_vec(t, delta_S_hat_1, data_mat_t_1, reg_param)\n",
    "    B_vec_1 = function_B_vec(t, Pi_hat_1)\n",
    "    phi_1 = np.dot(np.linalg.inv(A_mat_1), B_vec_1)\n",
    "    \n",
    "    a_op.loc[:,t] = np.dot(data_mat_t[t,:,:],phi) \n",
    "    a_op_1.loc[:,t] = np.dot(data_mat_t_1[t,:,:],phi_1) \n",
    "     \n",
    "    # 2. Now disturb these values by a random noise\n",
    "    noise_factors = np.random.uniform(low=1-eta, high=1+eta, size=N_MC)\n",
    "    a_op.loc[:, t] = noise_factors * a_op.loc[:, t]\n",
    "    a_op_1.loc[:, t] = noise_factors * a_op_1.loc[:, t]\n",
    "    \n",
    "    # 3. Compute portfolio values corresponding to observed actions\n",
    "    Pi_op.loc[:,t] = gamma * (Pi_op.loc[:,t+1] - a_op.loc[:,t] * delta_S.loc[:,t])\n",
    "    Pi_op_hat.loc[:,t] = Pi_op.loc[:,t] - np.mean(Pi_op.loc[:,t])\n",
    "    Pi_op_1.loc[:,t] = gamma * (Pi_op_1.loc[:,t+1] - a_op_1.loc[:,t] * delta_S_1.loc[:,t])\n",
    "    Pi_op_hat_1.loc[:,t] = Pi_op_1.loc[:,t] - np.mean(Pi_op_1.loc[:,t])\n",
    "    \n",
    "    # compute rewards corrresponding to observed actions\n",
    "    R_op.loc[1:,t] = gamma * a_op.loc[1:,t] * delta_S.loc[1:,t] - risk_lambda * np.var(Pi_op.loc[1:,t])\n",
    "    R_op_1.loc[1:,t] = gamma * a_op_1.loc[1:,t] * delta_S_1.loc[1:,t] - risk_lambda * np.var(Pi_op_1.loc[1:,t])\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override on-policy data with off-policy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_op.copy()\n",
    "a_1 = a_op_1.copy()\n",
    "\n",
    "Pi = Pi_op.copy()\n",
    "Pi_hat = Pi_op_hat.copy()\n",
    "Pi_1 = Pi_op_1.copy()\n",
    "Pi_hat_1 = Pi_op_hat_1.copy()\n",
    "\n",
    "R = R_op.copy()\n",
    "R_1 = R_op_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make matrix A_t of shape (3 x num_MC x num_steps)\n",
    "\n",
    "num_MC = a.shape[0]\n",
    "a_1_1 = a.values.reshape((1,num_MC,25))\n",
    "\n",
    "a_1_2 = 0.5 * a_1_1**2\n",
    "ones_3d = np.ones((1,num_MC, 25))\n",
    "\n",
    "A_stack = np.vstack((ones_3d, a_1_1, a_1_2))\n",
    "\n",
    "# and the same for the second dataset:\n",
    "a_2_1 = a_1.values.reshape((1,num_MC,25))\n",
    "a_2_2 = 0.5 * a_2_1**2\n",
    "A_stack_1 = np.vstack((ones_3d, a_2_1, a_2_2))\n",
    "\n",
    "print(A_stack.shape, A_stack_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a & a_1_1 shapes:', a.shape, a_1_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat_swap_idx = np.swapaxes(data_mat_t,0,2)\n",
    "data_mat_swap_idx_1 = np.swapaxes(data_mat_t_1,0,2)\n",
    "\n",
    "print(data_mat_swap_idx.shape) # (12, 10000, 25)\n",
    "\n",
    "# expand dimensions of matrices to multiply element-wise\n",
    "A_2 = np.expand_dims(A_stack, axis=1) # becomes (3,1,10000,25)\n",
    "data_mat_swap_idx = np.expand_dims(data_mat_swap_idx, axis=0)  # becomes (1,12,10000,25)\n",
    "\n",
    "Psi_mat = np.multiply(A_2, data_mat_swap_idx) # this is a matrix of size 3 x num_basis x num_MC x num_steps\n",
    "\n",
    "# now concatenate columns along the first dimension\n",
    "Psi_mat = Psi_mat.reshape(-1, N_MC, T+1, order='F')\n",
    "\n",
    "# the same for the twin dataset\n",
    "A_2_1 = np.expand_dims(A_stack_1, axis=1)\n",
    "data_mat_swap_idx_1 = np.expand_dims(data_mat_swap_idx_1, axis=0)\n",
    "\n",
    "Psi_mat_1 = np.multiply(A_2_1, data_mat_swap_idx_1) # this is a matrix of size 3 x num_basis x num_MC x num_steps\n",
    "\n",
    "# now concatenate columns along the first dimension\n",
    "Psi_mat_1 = Psi_mat_1.reshape(-1, N_MC, T+1, order='F')\n",
    "\n",
    "print(Psi_mat.shape, Psi_mat_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make matrix S_t \n",
    "\n",
    "Psi_1_aux = np.expand_dims(Psi_mat, axis=1)\n",
    "Psi_2_aux = np.expand_dims(Psi_mat, axis=0)\n",
    "print(Psi_1_aux.shape, Psi_2_aux.shape)\n",
    "\n",
    "S_t_mat = np.sum(np.multiply(Psi_1_aux, Psi_2_aux), axis=2) \n",
    "\n",
    "Psi_1_aux_1 = np.expand_dims(Psi_mat_1, axis=1)\n",
    "Psi_2_aux_1 = np.expand_dims(Psi_mat_1, axis=0)\n",
    "print(Psi_1_aux_1.shape, Psi_2_aux_1.shape)\n",
    "\n",
    "S_t_mat_1 = np.sum(np.multiply(Psi_1_aux_1, Psi_2_aux_1), axis=2) \n",
    "print(S_t_mat.shape, S_t_mat_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Psi_1_aux, Psi_2_aux, Psi_1_aux_1, Psi_2_aux_1, data_mat_swap_idx,data_mat_swap_idx_1, A_2, A_2_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector $\\vec W_t$ could be solved by\n",
    "\n",
    "$$\\vec W_t=\\mathbf S_t^{-1}\\mathbf M_t$$\n",
    "\n",
    "where $\\mathbf S_t$ and $\\mathbf M_t$ are matrix and vector respectively with elements given by\n",
    "\n",
    "$$S_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Psi_n\\left(X_t^k,a_t^k\\right)\\Psi_m\\left(X_t^k,a_t^k\\right)}\\quad\\quad M_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Psi_n\\left(X_t^k,a_t^k\\right)\\left(R_t\\left(X_t,a_t,X_{t+1}\\right)+\\gamma\\max_{a_{t+1}\\in\\mathcal{A}}Q_{t+1}^\\star\\left(X_{t+1},a_{t+1}\\right)\\right)}$$\n",
    "\n",
    "Define function *function_S* and *function_M* to compute the value of matrix $\\mathbf S_t$ and vector $\\mathbf M_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vectorized functions\n",
    "\n",
    "def function_S_vec(t,S_t_mat,reg_param):\n",
    "    # Compute the matrix S_{nm} from Eq. (75) (with a regularization!)\n",
    "    S_mat = S_t_mat[:,:,t]     \n",
    "    S_mat_reg = S_mat + reg_param * np.eye(S_mat.shape[0])\n",
    "    return S_mat_reg\n",
    "\n",
    "# this function requires some refinement!\n",
    "def function_M_vec(t,\n",
    "                   Q_star, # max_Q_star, \n",
    "                   R, \n",
    "                   Psi_mat_t,  # 2D array of dimension 3M x num_MC \n",
    "                   gamma=gamma):\n",
    "    \n",
    "    # Psi_mat = Psi_mat_t[:,:,t]   # 2D array of dimension 3M x num_MC \n",
    "    tmp = R.loc[:,t] + gamma * Q_star.iloc[:,t+1]\n",
    "    M_t = np.dot(Psi_mat_t, tmp.values)\n",
    "    return M_t\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call *function_S* and *function_M* for $t=T-1,...,0$ together with vector $\\vec\\Psi\\left(X_t,a_t\\right)$ to compute $\\vec W_t$ and learn the Q-function $Q_t^\\star\\left(X_t,a_t\\right)=\\mathbf A_t^T\\mathbf U_W\\left(t,X_t\\right)$ implied by the input data backward recursively with terminal condition $Q_T^\\star\\left(X_T,a_T=0\\right)=-\\Pi_T\\left(X_T\\right)-\\lambda Var\\left[\\Pi_T\\left(X_T\\right)\\right]$.\n",
    "\n",
    "When the vector $ \\vec{W}_t $ is computed as per the above at time $ t $, \n",
    "we can convert it back to a matrix $ \\bf{W}_t $ obtained from the vector $ \\vec{W}_t $ by \n",
    "reshaping to the shape $ 3 \\times M $.\n",
    "\n",
    "We can now calculate the matrix $ {\\bf U}_t $\n",
    "at time $ t $ for the whole set of MC paths as follows (this is Eq.(65) from the paper in a matrix form):\n",
    "\n",
    "$$  \\mathbf U_{W} \\left(t,X_t \\right) = \n",
    "\\left[\\begin{matrix} \\mathbf U_W^{0,k}\\left(t,X_t \\right) \\\\  \n",
    "\\mathbf U_W^{1,k}\\left(t,X_t \\right) \\\\ \\mathbf U_W^{2,k} \\left(t,X_t \\right)\n",
    "\\end{matrix}\\right]\n",
    "= \\bf{W}_t \\Phi_t \\left(t,X_t \\right)  $$\n",
    "\n",
    "Here the matrix $ {\\bf \\Phi}_t $ has the shape shape $ M \\times N_{MC}$. \n",
    "Therefore, their dot product has dimension $ 3 \\times N_{MC}$, as it should be. \n",
    "\n",
    "Once this matrix $ {\\bf U}_t $ is computed, individual vectors $ {\\bf U}_{W}^{1}, {\\bf U}_{W}^{2}, {\\bf U}_{W}^{3} $ for all MC paths are read off as rows of this matrix.\n",
    "\n",
    "From here, we can compute the optimal action and optimal Q-function $Q^{\\star}(X_t, a_t^{\\star}) $ at the optimal action for a given step $ t $. This will be used to evaluate the $ \\max_{a_{t+1} \\in \\mathcal{A}} Q^{\\star} \\left(X_{t+1}, a_{t+1} \\right) $.\n",
    "\n",
    "\n",
    "The optimal action and optimal Q-function with the optimal action could be computed by\n",
    "\n",
    "$$a_t^\\star\\left(X_t\\right)=\\frac{\\mathbb{E}_{t} \\left[  \\Delta \\hat{S}_{t}  \\hat{\\Pi}_{t+1} + \\frac{1}{2 \\gamma \\lambda} \\Delta S_{t} \\right]}{\n",
    "  \\mathbb{E}_{t} \\left[ \\left( \\Delta \\hat{S}_{t} \\right)^2 \\right]}\\, , \n",
    "\\quad\\quad Q_t^\\star\\left(X_t,a_t^\\star\\right)=\\mathbf U_W^{\\left(0\\right)}\\left(t,X_t\\right)+ a_t^\\star \\mathbf U_W^{\\left(2\\right)}\\left(t,X_t\\right) +\\frac{1}{2}\\left(a_t^\\star\\right)^2\\mathbf U_W^{\\left(2\\right)}\\left(t,X_t\\right)$$\n",
    "\n",
    "with terminal condition $a_T^\\star=0$ and $Q_T^\\star\\left(X_T,a_T^\\star=0\\right)=-\\Pi_T\\left(X_T\\right)-\\lambda Var\\left[\\Pi_T\\left(X_T\\right)\\right]$.\n",
    "\n",
    "Plots of 5 optimal action $a_t^\\star\\left(X_t\\right)$, optimal Q-function with optimal action $Q_t^\\star\\left(X_t,a_t^\\star\\right)$ and implied Q-function $Q_t^\\star\\left(X_t,a_t\\right)$ paths are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted Q Iteration (FQI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "# implied Q-function by input data (using the first form in Eq.(68))\n",
    "Q_RL = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Q_RL.iloc[:,-1] = - Pi.iloc[:,-1] - risk_lambda * np.var(Pi.iloc[:,-1])\n",
    "\n",
    "# similar variables for the twin dataset:\n",
    "Q_RL_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Q_RL_1.iloc[:,-1] = - Pi_1.iloc[:,-1] - risk_lambda * np.var(Pi_1.iloc[:,-1])\n",
    "\n",
    "# optimal action\n",
    "a_opt = np.zeros((N_MC,T+1))\n",
    "a_star = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a_star.iloc[:,-1] = 0\n",
    "\n",
    "# optimal action\n",
    "a_opt_1 = np.zeros((N_MC,T+1))\n",
    "a_star_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "a_star_1.iloc[:,-1] = 0\n",
    "\n",
    "# optimal Q-function with optimal action\n",
    "Q_star = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Q_star.iloc[:,-1] = Q_RL.iloc[:,-1]\n",
    "\n",
    "# optimal Q-function with optimal action\n",
    "Q_star_1 = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
    "Q_star_1.iloc[:,-1] = Q_RL_1.iloc[:,-1]\n",
    "\n",
    "max_Q_star = np.zeros((N_MC,T+1))\n",
    "max_Q_star[:,-1] = Q_RL.iloc[:,-1].values\n",
    "\n",
    "max_Q_star_1 = np.zeros((N_MC,T+1))\n",
    "max_Q_star_1[:,-1] = Q_RL_1.iloc[:,-1].values\n",
    "\n",
    "num_basis = data_mat_t.shape[2]\n",
    "\n",
    "reg_param = 1e-3\n",
    "hyper_param =  1e-1\n",
    "\n",
    "# The backward loop\n",
    "for t in range(T-1, -1, -1):\n",
    "    # calculate vector W_t\n",
    "    S_mat_reg = function_S_vec(t,S_t_mat,reg_param) \n",
    "    M_t = function_M_vec(t,Q_star, R, Psi_mat[:,:,t], gamma)\n",
    "    W_t = np.dot(np.linalg.inv(S_mat_reg),M_t)  # this is an 1D array of dimension 3M\n",
    "    \n",
    "    # reshape to a matrix W_mat  \n",
    "    W_mat = W_t.reshape((3, num_basis), order='F')  # shape 3 x M \n",
    "        \n",
    "    # make matrix Phi_mat\n",
    "    Phi_mat = data_mat_t[t,:,:].T  # dimension M x N_MC\n",
    "\n",
    "    # compute matrix U_mat of dimension N_MC x 3 \n",
    "    U_mat = np.dot(W_mat, Phi_mat)\n",
    "    \n",
    "    # twin variables for the twin dataset:\n",
    "    S_mat_reg_1 = function_S_vec(t,S_t_mat_1,reg_param) \n",
    "    M_t_1 = function_M_vec(t,Q_star_1, R_1, Psi_mat_1[:,:,t], gamma)\n",
    "    W_t_1 = np.dot(np.linalg.inv(S_mat_reg_1),M_t_1)  # this is an 1D array of dimension 3M\n",
    "    \n",
    "    # reshape to a matrix W_mat  \n",
    "    W_mat_1 = W_t_1.reshape((3, num_basis), order='F')  # shape 3 x M \n",
    "        \n",
    "    # make matrix Phi_mat\n",
    "    Phi_mat_1 = data_mat_t_1[t,:,:].T  # dimension M x N_MC\n",
    "\n",
    "    # compute matrix U_mat_1 of dimension N_MC x 3 \n",
    "    U_mat_1 = np.dot(W_mat_1, Phi_mat_1)\n",
    "    \n",
    "    # compute vectors U_W^0,U_W^1,U_W^2 as rows of matrix U_mat  \n",
    "    U_W_0 = U_mat[0,:]\n",
    "    U_W_1 = U_mat[1,:]\n",
    "    U_W_2 = U_mat[2,:]\n",
    "    \n",
    "    U_W_0_1 = U_mat_1[0,:]\n",
    "    U_W_1_1 = U_mat_1[1,:]\n",
    "    U_W_2_1 = U_mat_1[2,:]\n",
    "     \n",
    "    # IMPORTANT!!! Instead, use hedges computed as in DP approach:\n",
    "    # in this way, errors of function approximation do not back-propagate. \n",
    "    # This provides a stable solution, unlike\n",
    "    # the first method that leads to a diverging solution \n",
    "    A_mat = function_A_vec(t,delta_S_hat,data_mat_t,reg_param)\n",
    "    B_vec = function_B_vec(t, Pi_hat)\n",
    "    phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
    "    \n",
    "    A_mat_1 = function_A_vec(t,delta_S_hat_1,data_mat_t_1,reg_param)\n",
    "    B_vec_1 = function_B_vec(t, Pi_hat_1)\n",
    "\n",
    "    phi_1 = np.dot(np.linalg.inv(A_mat_1), B_vec_1)\n",
    "    \n",
    "    a_opt[:,t] = np.dot(data_mat_t[t,:,:],phi)\n",
    "    a_star.loc[:,t] = a_opt[:,t] \n",
    "    \n",
    "    a_opt_1[:,t] = np.dot(data_mat_t_1[t,:,:],phi_1)\n",
    "    a_star_1.loc[:,t] = a_opt_1[:,t] \n",
    "    \n",
    "    max_Q_star[:,t] = U_W_0 + a_opt[:,t] * U_W_1 + 0.5 * (a_opt[:,t]**2) * U_W_2 \n",
    "    max_Q_star_1[:,t] = U_W_0_1 + a_opt_1[:,t] * U_W_1_1 + 0.5 * (a_opt_1[:,t]**2) * U_W_2_1 \n",
    "      \n",
    "    # update dataframes     \n",
    "    Q_star.loc[:,t] = max_Q_star[:,t]\n",
    "    \n",
    "    # update the Q_RL solution given by a dot product of two matrices W_t Psi_t\n",
    "    Psi_t = Psi_mat[:,:,t].T  # dimension N_MC x 3M  \n",
    "    Q_RL.loc[:,t] = np.dot(Psi_t, W_t)\n",
    "    \n",
    "    a_star_1.loc[:,t] = a_opt_1[:,t] \n",
    "    Q_star_1.loc[:,t] = max_Q_star_1[:,t]\n",
    "    \n",
    "    # update the Q_RL solution given by a dot product of two matrices W_t Psi_t\n",
    "    Psi_t_1 = Psi_mat_1[:,:,t].T  # dimension N_MC x 3M  \n",
    "    Q_RL_1.loc[:,t] = np.dot(Psi_t_1, W_t_1)\n",
    "    \n",
    "    # trim outliers for Q_RL\n",
    "    up_percentile_Q_RL =  95 # 95\n",
    "    low_percentile_Q_RL = 5 # 5\n",
    "    \n",
    "    low_perc_Q_RL, up_perc_Q_RL = np.percentile(Q_RL.loc[:,t],[low_percentile_Q_RL,up_percentile_Q_RL])\n",
    "    \n",
    "    # trim outliers in values of max_Q_star:\n",
    "    flag_lower = Q_RL.loc[:,t].values < low_perc_Q_RL\n",
    "    flag_upper = Q_RL.loc[:,t].values > up_perc_Q_RL\n",
    "    Q_RL.loc[flag_lower,t] = low_perc_Q_RL\n",
    "    Q_RL.loc[flag_upper,t] = up_perc_Q_RL\n",
    "    \n",
    "    low_perc_Q_RL_1, up_perc_Q_RL_1 = np.percentile(Q_RL_1.loc[:,t],[low_percentile_Q_RL,up_percentile_Q_RL])\n",
    "   \n",
    "    # trim outliers in values of max_Q_star:\n",
    "    flag_lower_1 = Q_RL_1.loc[:,t].values < low_perc_Q_RL_1\n",
    "    flag_upper_1 = Q_RL_1.loc[:,t].values > up_perc_Q_RL_1\n",
    "    Q_RL_1.loc[flag_lower_1,t] = low_perc_Q_RL_1\n",
    "    Q_RL_1.loc[flag_upper_1,t] = up_perc_Q_RL_1\n",
    "    \n",
    "endtime = time.time()\n",
    "print('\\nTime Cost:', endtime - starttime, 'seconds')\n",
    "\n",
    "f, axarr = plt.subplots(3, 2)\n",
    "f.subplots_adjust(hspace=.5)\n",
    "f.set_figheight(8.0)\n",
    "f.set_figwidth(8.0)\n",
    "\n",
    "step_size = N_MC // 10\n",
    "idx_plot = np.arange(step_size, N_MC, step_size)\n",
    "axarr[0, 0].plot(a_star.T.iloc[:, idx_plot]) \n",
    "axarr[0, 0].set_xlabel('Time Steps')\n",
    "axarr[0, 0].set_title(r'Optimal action $a_t^{\\star}$')\n",
    "\n",
    "axarr[0, 1].plot(a_star_1.T.iloc[:, idx_plot]) \n",
    "axarr[0, 1].set_xlabel('Time Steps')\n",
    "axarr[0, 1].set_title(r'Optimal action $a_t^{\\star}$')\n",
    "\n",
    "axarr[1, 0].plot(Q_RL.T.iloc[:, idx_plot]) \n",
    "axarr[1, 0].set_xlabel('Time Steps')\n",
    "axarr[1, 0].set_title(r'Q-function $Q_t^{\\star} (X_t, a_t)$')\n",
    "\n",
    "axarr[1, 1].plot(Q_RL_1.T.iloc[:, idx_plot]) \n",
    "axarr[1, 1].set_xlabel('Time Steps')\n",
    "axarr[1, 1].set_title(r'Q-function $Q_t^{\\star}(X_t, a_t)$')\n",
    "\n",
    "axarr[2, 0].plot(Q_star.T.iloc[:, idx_plot]) \n",
    "axarr[2, 0].set_xlabel('Time Steps')\n",
    "axarr[2, 0].set_title(r'Optimal Q-function $Q_t^{\\star} (X_t, a_t^{\\star})$') \n",
    "\n",
    "axarr[2, 1].plot(Q_star_1.T.iloc[:, idx_plot]) \n",
    "axarr[2, 1].set_xlabel('Time Steps')\n",
    "axarr[2, 1].set_title(r'Optimal Q-function $Q_t^{\\star} (X_t, a_t^{\\star})$')\n",
    "\n",
    "plt.savefig('QLBS_FQI_off_policy_summary_ATM_eta_%d.png' % (100 * eta), dpi=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the optimal action $a_t^\\star\\left(X_t\\right)$ and optimal Q-function with optimal action $Q_t^\\star\\left(X_t,a_t^\\star\\right)$ given by Dynamic Programming and Reinforcement Learning.\n",
    "\n",
    "Plots of 1 path comparisons are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a and a_star\n",
    "# plot 1 path\n",
    "\n",
    "num_path =  120\n",
    "\n",
    "# Note that a from the DP method and a_star from the RL method are now identical by construction\n",
    "plt.plot(a.T.iloc[:,num_path], label=\"DP Action\")\n",
    "plt.plot(a_star.T.iloc[:,num_path], label=\"RL Action\")\n",
    "plt.legend()\n",
    "plt.xlabel('Time Steps')\n",
    "plt.title('Optimal Action Comparison Between DP and RL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the RL-based pricing with QLBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLBS option price\n",
    "C_QLBS = - Q_star.copy()\n",
    "C_QLBS_1 = - Q_star_1.copy()\n",
    "\n",
    "print('---------------------------------')\n",
    "print('       QLBS RL Option Pricing       ')\n",
    "print('---------------------------------\\n')\n",
    "print('%-25s' % ('Initial Stock Price:'), S0)\n",
    "print('%-25s' % ('Drift of Stock:'), mu)\n",
    "print('%-25s' % ('Volatility of Stock:'), sigma)\n",
    "print('%-25s' % ('Risk-free Rate:'), r)\n",
    "print('%-25s' % ('Risk aversion parameter :'), risk_lambda)\n",
    "print('%-25s' % ('Strike:'), K)\n",
    "print('%-25s' % ('Maturity:'), M)\n",
    "print('%-26s %.4f' % ('\\nThe QLBS Put Price 1 :', (np.mean(C_QLBS.iloc[:,0]))))\n",
    "print('%-26s %.4f' % ('\\nThe QLBS Put Price 2 :', (np.mean(C_QLBS_1.iloc[:,0]))))\n",
    "\n",
    "\n",
    "QLBS_prices = np.array([C_QLBS.iloc[0,0],C_QLBS_1.iloc[0,0]])\n",
    "mean_price = np.mean(QLBS_prices)\n",
    "std_price = np.std(QLBS_prices)\n",
    "\n",
    "print('%-26s  %.4f +/- %.4f ' % ('QLBS Put Price: ',mean_price,std_price ))\n",
    "print('%-26s %.4f' % ('\\nBlack-Sholes Put Price:', bs_put(0)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add here calculation of different MC runs (6 repetitions of action randomization)\n",
    "\n",
    "# on-policy values\n",
    "y1_onp = 5.0211 # 4.9170\n",
    "y2_onp = 4.7798 # 7.6500\n",
    "\n",
    "# QLBS_price_on_policy = 4.9004 +/- 0.1206\n",
    "\n",
    "# these are the results for noise eta = 0.15\n",
    "# p1 = np.array([5.0174, 4.9249, 4.9191, 4.9039, 4.9705, 4.6216 ])\n",
    "# p2 = np.array([6.3254, 8.6733, 8.0686, 7.5355, 7.1751, 7.1959 ])\n",
    "\n",
    "p1 = np.array([5.0485, 5.0382, 5.0211, 5.0532, 5.0184])\n",
    "p2 = np.array([4.7778, 4.7853, 4.7781,4.7805, 4.7828])\n",
    "\n",
    "# results for eta = 0.25\n",
    "# p3 = np.array([4.9339, 4.9243, 4.9224, 5.1643, 5.0449, 4.9176 ])\n",
    "# p4 = np.array([7.7696,8.1922, 7.5440,7.2285, 5.6306, 12.6072])\n",
    "\n",
    "p3 = np.array([5.0147, 5.0445, 5.1047, 5.0644, 5.0524])\n",
    "p4 = np.array([4.7842,4.7873, 4.7847, 4.7792, 4.7796])\n",
    "\n",
    "# eta = 0.35 \n",
    "# p7 = np.array([4.9718, 4.9528, 5.0170, 4.7138, 4.9212, 4.6058])\n",
    "# p8 = np.array([8.2860, 7.4012, 7.2492, 8.9926, 6.2443, 6.7755])\n",
    "\n",
    "p7 = np.array([5.1342, 5.2288, 5.0905, 5.0784, 5.0013 ])\n",
    "p8 = np.array([4.7762, 4.7813,4.7789, 4.7811, 4.7801])\n",
    "\n",
    "# results for eta = 0.5\n",
    "# p5 = np.array([4.9446, 4.9894,6.7388, 4.7938,6.1590, 4.5935 ])\n",
    "# p6 = np.array([7.5632, 7.9250, 6.3491, 7.3830, 13.7668, 14.6367 ])\n",
    "\n",
    "p5 = np.array([3.1459, 4.9673, 4.9348, 5.2998, 5.0636 ])\n",
    "p6 = np.array([4.7816, 4.7814, 4.7834, 4.7735, 4.7768])\n",
    "x = np.array([0.15, 0.25, 0.35, 0.5])\n",
    "y1 = np.array([np.mean(p1), np.mean(p3), np.mean(p7), np.mean(p5)])\n",
    "y2 = np.array([np.mean(p2), np.mean(p4), np.mean(p8), np.mean(p6)])\n",
    "y_err_1 = np.array([np.std(p1), np.std(p3),np.std(p7),  np.std(p5)])\n",
    "y_err_2 = np.array([np.std(p2), np.std(p4), np.std(p8), np.std(p6)])\n",
    "\n",
    "# plot it \n",
    "f, axs = plt.subplots(nrows=2, ncols=2, sharex=True)\n",
    "\n",
    "f.subplots_adjust(hspace=.5)\n",
    "f.set_figheight(6.0)\n",
    "f.set_figwidth(8.0)\n",
    "\n",
    "ax = axs[0,0]\n",
    "ax.plot(x, y1)\n",
    "ax.axhline(y=y1_onp,linewidth=2, color='r')\n",
    "textstr = 'On-policy value = %2.2f'% (y1_onp)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)                      \n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.05, 0.15, textstr, fontsize=11,transform=ax.transAxes, verticalalignment='top', bbox=props)\n",
    "ax.set_title('Mean option price')\n",
    "ax.set_xlabel('Noise level')\n",
    "\n",
    "ax = axs[0,1]\n",
    "ax.plot(x, y2)\n",
    "ax.axhline(y=y2_onp,linewidth=2, color='r')\n",
    "textstr = 'On-policy value = %2.2f'% (y2_onp)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)     \n",
    "\n",
    "# place a text box in upper left in axes coords\n",
    "ax.text(0.35, 0.95, textstr, fontsize=11,transform=ax.transAxes, verticalalignment='top', bbox=props)\n",
    "ax.set_title('Mean option price')\n",
    "ax.set_xlabel('Noise level')\n",
    "\n",
    "ax = axs[1,0]\n",
    "ax.plot(x, y_err_1)\n",
    "ax.set_title('Std of option price')\n",
    "ax.set_xlabel('Noise level')\n",
    "\n",
    "ax = axs[1,1]\n",
    "ax.plot(x, y_err_2)\n",
    "ax.set_title('Std of option price')\n",
    "ax.set_xlabel('Noise level')\n",
    "\n",
    "f.suptitle('Mean and std of option price vs noise level')\n",
    "\n",
    "plt.savefig('Option_price_vs_noise_level.png', dpi=600);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
