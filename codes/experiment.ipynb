{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJT6KnQbwv5x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import bspline\n",
        "import bspline.splinelab as splinelab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzEoaP7Vw3fE"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"Assets.csv\")\n",
        "# ['Year', 'Total Assets', 'Log Return', 'Yearly Volatility','Quarterly Volatility', 'Distress Barrier', 'Moody\\'s Ratings', 'Past RNPD', 'Normalized Past RNPD']\n",
        "# print(data.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Log Return', 'Yearly Volatility', 'Quarter Volatility'])\n",
        "\n",
        "# start_year=2001\n",
        "# end_year=2022\n",
        "\n",
        "# dataset['Year']=np.arange(start_year, end_year+1)\n",
        "# dataset['Total Assets']= pd.Series([71753078142.00, 73535346705.00, 78235030416.00, 87355506463.00, 105912000000.00, 114571000000.00, 113550000000.00, 120751000000.00, 117451000000.00, 116042000000.00, 110884000000.00, 107309000000.00, 116030000000.00, 139673000000.00, 154796000000.00, 161894000000.00, 208396000000.00, 209056000000.00, 189460000000.00, 203829000000.00, 234233000000.00, 223807000000.00], dtype='float')\n",
        "# dataset['Distress Barrier']=pd.Series([15669733148, 16622163564, 17776465778, 17833508474, 16877445036, 18517386840, 21442068690, 23291326752, 24542066485, 28766631090, 29199892732, 30006391296, 29813639417, 32344507489, 34364836658, 37469268824, 46353699857, 50017932700, 54655855964, 57011267289, 64287512856, 69763695000], dtype='float')\n",
        "# for t in range(1, end_year+1-start_year):\n",
        "#     dataset.iloc[t,3]=np.log(dataset.iloc[t,1] / dataset.iloc[t-1, 1]) #filling Log return\n",
        "\n",
        "# dataset['Log Return']= dataset['Log Return'].astype('float')\n",
        "# for i in range(2, end_year+1-start_year):\n",
        "#     returns=np.array(dataset.iloc[1:i+1, 3])\n",
        "#     yrly_vol=np.std(a=returns, dtype='float', ddof=1)*(np.sqrt(261))\n",
        "#     dataset.iloc[i, 4]=yrly_vol\n",
        "#     dataset.iloc[i, 5]=yrly_vol/np.sqrt(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Past RNPD', \"Def Probability\", 'Moody\\'s Ratings', 'Normalized Past RNPD'])\n",
        "# later add min max normalized Default Probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Log Return', 'Yearly Volatility', 'Quarter Volatility'])\n",
        "\n",
        "# start_year=2001\n",
        "# end_year=2022\n",
        "\n",
        "# dataset['Year']=np.arange(start_year, end_year+1)\n",
        "# dataset['Total Assets']= pd.Series([71753078142.00, 73535346705.00, 78235030416.00, 87355506463.00, 105912000000.00, 114571000000.00, 113550000000.00, 120751000000.00, 117451000000.00, 116042000000.00, 110884000000.00, 107309000000.00, 116030000000.00, 139673000000.00, 154796000000.00, 161894000000.00, 208396000000.00, 209056000000.00, 189460000000.00, 203829000000.00, 234233000000.00, 223807000000.00], dtype='float')\n",
        "# dataset['Distress Barrier']=pd.Series([15669733148, 16622163564, 17776465778, 17833508474, 16877445036, 18517386840, 21442068690, 23291326752, 24542066485, 28766631090, 29199892732, 30006391296, 29813639417, 32344507489, 34364836658, 37469268824, 46353699857, 50017932700, 54655855964, 57011267289, 64287512856, 69763695000], dtype='float')\n",
        "# for t in range(1, end_year+1-start_year):\n",
        "#     dataset.iloc[t,3]=np.log(dataset.iloc[t,1] / dataset.iloc[t-1, 1]) #filling Log return\n",
        "\n",
        "# dataset['Log Return']= dataset['Log Return'].astype('float')\n",
        "# for i in range(2, end_year+1-start_year):\n",
        "#     returns=np.array(dataset.iloc[1:i+1, 3])\n",
        "#     yrly_vol=np.std(a=returns, dtype='float', ddof=1)*(np.sqrt(261))\n",
        "#     dataset.iloc[i, 4]=yrly_vol\n",
        "#     dataset.iloc[i, 5]=yrly_vol/np.sqrt(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVejKJ8kw3UR"
      },
      "outputs": [],
      "source": [
        "new_mat_og=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Volatility - Year', 'Volatility - Quarter', 'Quarter Number', 'N(d1)', 'd1', 'd2', 'N(-d2)', 'Moody\\'s Rating'])\n",
        "# we will have T+1 values per year, per simulation, qtr num onwards all unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7Z3vP4Qw2_L"
      },
      "outputs": [],
      "source": [
        "mu = 0.005   # drift\n",
        "r = 0.124     # risk-free rate\n",
        "T = 4\n",
        "M = 1         # maturity\n",
        "N_MC = 2500    # number of paths\n",
        "risk_lambda = 0.6\n",
        " # risk aversion parameter\n",
        "delta_t = M / T                # time interval\n",
        "gamma = np.exp(- r * delta_t)  # discount factor\n",
        "# Define the risk aversion parameter\n",
        "reg_param = 1e-3\n",
        "\n",
        "# To get meaninful results, one should have ncolloc >= p+1\n",
        "p = 4 # order of spline (as-is; 3: cubic, 4: B-spline?)\n",
        "ncolloc = 12\n",
        "\n",
        "num_t_steps = T + 1\n",
        "num_basis =  ncolloc\n",
        "\n",
        "year_avg=np.arange(0.0, 21.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0dtfMK8xA8x"
      },
      "outputs": [],
      "source": [
        "# standard normal random numbers\n",
        "RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL3tV8EFxA5X"
      },
      "outputs": [],
      "source": [
        "def terminal_payoff(ST, K):\n",
        "    # ST   final stock price    # K    strike\n",
        "    payoff = max(K - ST, 0)\n",
        "    return payoff\n",
        "\n",
        "\n",
        "# functions to compute optimal hedges\n",
        "def function_A_vec(t,delta_S_hat,data_mat_t):\n",
        "    # Compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
        "    X_mat = data_mat_t[t,:,:]\n",
        "    num_basis_funcs = X_mat.shape[1]\n",
        "    this_dS = delta_S_hat.loc[:,t].values\n",
        "    hat_dS2 = (this_dS**2).reshape(-1,1)\n",
        "    A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n",
        "    return A_mat\n",
        "\n",
        "\n",
        "def function_B_vec(t, Pi_hat, delta_S_hat, S, data_mat_t):\n",
        "    coef = 1.0/(2 * gamma * risk_lambda)\n",
        "    tmp =  Pi_hat.loc[:,t+1] * delta_S_hat.loc[:,t] + coef * (np.exp(mu*delta_t) - np.exp(r*delta_t))* S.loc[:,t]\n",
        "    X_mat = data_mat_t[t,:,:]  # matrix of dimension N_MC x num_basis\n",
        "    B = np.dot(X_mat.T, tmp)\n",
        "    return B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euJCKshwxA1Q"
      },
      "outputs": [],
      "source": [
        "for i in range(2, 22): #use this to mean from 2002 to 2022\n",
        "    count=i\n",
        "    curr_yr_avg=np.arange(0.0, T+2.0)\n",
        "\n",
        "    curr_year=i+2001\n",
        "\n",
        "    print(\"\\nYear \", curr_year, \". Simulation\", i-1,\"/20.\")\n",
        "\n",
        "    year=data.iloc[i, 0]\n",
        "    S0=data.iloc[i, 1]                 #initial stock price\n",
        "    S0=S0/1000000000\n",
        "    sigma=data.iloc[i, 3]              # yearly volatility\n",
        "    sigma_qtr=data.iloc[i, 4]          # quarterly volatility\n",
        "    K=data.iloc[i, 5]\n",
        "    K=K/1000000000\n",
        "    moody=data.iloc[i, 6]\n",
        "\n",
        "    # # standard normal random numbers\n",
        "    # RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))\n",
        "\n",
        "    # print(\"year: \", year)\n",
        "    # print(\"S0: \", S0)\n",
        "    # print(\"sigma: \", sigma)\n",
        "    # print(\"sigma_qtr: \", sigma_qtr)\n",
        "    # print(\"K: \", K)\n",
        "\n",
        "    S = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    S.loc[:,0] = S0\n",
        "    # print(\"S\\n\", S.head)\n",
        "\n",
        "    for t in range(1, T+1):\n",
        "        S.loc[:,t] = S.loc[:,t-1] * np.exp((mu - 1/2 * sigma**2) * delta_t + sigma * np.sqrt(delta_t) * RN.loc[:,t])\n",
        "\n",
        "    # print(\"S\\n\", S.head)\n",
        "\n",
        "    delta_S = S.loc[:,1:T].values - np.exp(r * delta_t) * S.loc[:,0:T-1]\n",
        "    delta_S_hat = delta_S.apply(lambda x: x - np.mean(x), axis=0)\n",
        "\n",
        "    # state variable\n",
        "    X = - (mu - 1/2 * sigma**2) * np.arange(T+1) * delta_t + np.log(S.astype(float) / 1.0)  # delta_t here is due to their conventions\n",
        "    # print(\"X\\n\", X.head)\n",
        "\n",
        "    X_min = np.min(np.min(X))\n",
        "    X_max = np.max(np.max(X))\n",
        "\n",
        "    tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n",
        "\n",
        "    # k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n",
        "    k = splinelab.aptknt(tau, p)\n",
        "    # print(\"k: \", k)\n",
        "\n",
        "    # Spline basis of order p on knots k\n",
        "    basis = bspline.Bspline(k, p)\n",
        "    f = plt.figure()\n",
        "    # basis.plot()\n",
        "\n",
        "    # Make data matrices with feature values\n",
        "    data_mat_t = np.zeros((num_t_steps, N_MC, num_basis))\n",
        "\n",
        "    # fill it\n",
        "    for i in np.arange(num_t_steps):\n",
        "        x = X.values[:,i]\n",
        "        basis_arr=np.array([ basis(i) for i in x ])\n",
        "        data_mat_t[i,:,:] = basis_arr\n",
        "\n",
        "    # Compute optimal hedge and portfolio value\n",
        "    # portfolio value\n",
        "    Pi = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    Pi.iloc[:,-1] = S.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
        "\n",
        "    Pi_hat = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    Pi_hat.iloc[:,-1] = Pi.iloc[:,-1] - np.mean(Pi.iloc[:,-1])\n",
        "\n",
        "    # optimal hedge\n",
        "    a = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "\n",
        "    a.iloc[:,-1] = 0\n",
        "\n",
        "    for t in range(T-1, -1, -1):\n",
        "\n",
        "        A_mat = function_A_vec(t, delta_S_hat, data_mat_t)\n",
        "        B_vec = function_B_vec(t, Pi_hat, delta_S_hat, S, data_mat_t)\n",
        "\n",
        "        # Convert A_mat and B_vec to a NumPy array of floats\n",
        "        A_mat = np.array(A_mat, dtype=float)\n",
        "        B_vec = np.array(B_vec, dtype=float)\n",
        "\n",
        "        phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
        "        a.loc[:,t] = np.dot(data_mat_t[t,:,:],phi)\n",
        "        Pi.loc[:,t] = gamma * (Pi.loc[:,t+1] - a.loc[:,t] * delta_S.loc[:,t])\n",
        "        Pi_hat.loc[:,t] = Pi.loc[:,t] - np.mean(Pi.loc[:,t])\n",
        "\n",
        "    # print(\"a\\n\", a.head)\n",
        "    # print(\"Pi\\n\", Pi.head)\n",
        "\n",
        "    a_avg=a.mean()\n",
        "\n",
        "\n",
        "    # using Nd1 as is, 5 data points\n",
        "    Nd1_og=a_avg.astype(float)\n",
        "    # using zscore to get from Nd1 to d1\n",
        "    \n",
        "    d1_og = stats.zscore(Nd1_og)\n",
        "    # print(\"D1:\\n\",d1_og)e\n",
        "\n",
        "\n",
        "\n",
        "    # where T is the total number of timesteps\n",
        "    # the variable qtr is an iterator over the Timesteps, starting from O to T\n",
        "    # so it runs for a total of T+1 times (it T =2, qtr=[0,1,2])\n",
        "    for qtr in range(0,T+1): #in range(a,b), a in inclusive and b is exclusive\n",
        "        # print(qtr)\n",
        "        \n",
        "        this_Nd1_og=Nd1_og[qtr]\n",
        "        this_d1_og=d1_og[qtr]\n",
        "\n",
        "        d2_og=this_d1_og-(sigma_qtr*np.sqrt((T-qtr)/T))\n",
        "        # print(\"d2_og: \", d2_og)\n",
        "\n",
        "        Nd2_og=norm.cdf(-d2_og)\n",
        "        # print(\"N(-d2_og): \", Nd2_og)\n",
        "\n",
        "\n",
        "        # LCL = (S0*this_Nd1_og)-(K*Nposd2_og*np.exp(r*T))\n",
        "\n",
        "        new_row_og =[year, S0, K, sigma, sigma_qtr, qtr, Nd1_og[qtr], d1_og[qtr], d2_og, Nd2_og, moody]\n",
        "        # print(new_row_og)\n",
        "        new_mat_og.loc[len(new_mat_og)] = new_row_og\n",
        "        curr_yr_avg[qtr]=Nd2_og\n",
        "        # print(curr_yr_avg[qtr])\n",
        "    \n",
        "    sum=0\n",
        "    for i in range(0,T+1):\n",
        "        sum+=curr_yr_avg[i]\n",
        "    yr_avg=sum/T\n",
        "\n",
        "    # data = ['Year', 'Total Assets', 'Log Return', 'Yearly Volatility','Quarterly Volatility', 'Distress Barrier', 'Moody\\'s Ratings', 'Past RNPD', 'Normalized Past RNPD']\n",
        "    #output = 'Year', 'Total Assets', 'Distress Barrier', 'Past RNPD', \"Def Probability\", 'Moody\\'s Ratings', 'Normalized Past RNPD'])\n",
        "    new_output_row=[year, data.iloc[count, 1],  data.iloc[count, 5], data.iloc[count, 7], yr_avg, data.iloc[count, 6], data.iloc[count, 8]]\n",
        "    output.loc[len(output)] = new_output_row\n",
        "    # print(\"\\nloop over\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add min max norm of def probability\n",
        "\n",
        "# Calculate min and max of 'Def Probability'\n",
        "min_prob = output['Def Probability'].min()\n",
        "max_prob = output['Def Probability'].max()\n",
        "\n",
        "# Create a new column with normalized values\n",
        "output['Normalized Def Probability'] = (output['Def Probability'] - min_prob) / (max_prob - min_prob)\n",
        "\n",
        "us=output['Normalized Def Probability']\n",
        "moody=output['Moody\\'s Ratings']\n",
        "exesum=output['Normalized Past RNPD']\n",
        "output['EucDist - Moody vs Us'] = (np.sqrt((us-moody)**2))\n",
        "output['EucDist - Moody vs ExeSum'] = (np.sqrt((exesum-moody)**2))\n",
        "output['EucDist - Us vs ExeSum'] = (np.sqrt((us-exesum)**2))\n",
        "\n",
        "output[\"Compare RNPD\"] = [0.6305035, 0.63923975,\t0.61812033,\t0.65817712,\t0.71738401,\t0.78523653,\t0.79311,\t0.80536048,\t0.83774903,\t0.8355024,\t0.79626415,\t0.82442427,\t0.74055703,\t0.70127537,\t0.65587051,\t0.71405749,\t0.85471027,\t0.75278117,\t0.76817475,\t0.84146686]\n",
        "output[\"Compare Norm RNPD\"] = [0.05234022, 0.08926593, 0,         0.16930893,  0.41956002, 0.70635379, 0.73963276, 0.79141214, 0.92830955, 0.91881367, 0.75296448, 0.87198949, 0.51750594, 0.35147327, 0.15955953, 0.40549974, 1,         0.56917399, 0.63423838, 0.94402378]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD2cbr_zxAyM"
      },
      "outputs": [],
      "source": [
        "# print(\"Original\\n\", new_mat_og)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "# Probability (quantile)\n",
        "prob = -0.03\n",
        "\n",
        "# Calculate the inverse CDF (95th percentile)\n",
        "value = stats.norm.ppf(prob, loc=mean, scale=std_dev)\n",
        "print(value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
