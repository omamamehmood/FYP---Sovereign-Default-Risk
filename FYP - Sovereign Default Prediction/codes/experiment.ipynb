{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SJT6KnQbwv5x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import bspline\n",
        "import bspline.splinelab as splinelab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xzEoaP7Vw3fE"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"Assets.csv\")\n",
        "# ['Year', 'Total Assets', 'Log Return', 'Yearly Volatility','Quarterly Volatility', 'Distress Barrier', 'Moody\\'s Ratings', 'Past RNPD', 'Normalized Past RNPD']\n",
        "# print(data.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Log Return', 'Yearly Volatility', 'Quarter Volatility'])\n",
        "\n",
        "# start_year=2001\n",
        "# end_year=2022\n",
        "\n",
        "# dataset['Year']=np.arange(start_year, end_year+1)\n",
        "# dataset['Total Assets']= pd.Series([71753078142.00, 73535346705.00, 78235030416.00, 87355506463.00, 105912000000.00, 114571000000.00, 113550000000.00, 120751000000.00, 117451000000.00, 116042000000.00, 110884000000.00, 107309000000.00, 116030000000.00, 139673000000.00, 154796000000.00, 161894000000.00, 208396000000.00, 209056000000.00, 189460000000.00, 203829000000.00, 234233000000.00, 223807000000.00], dtype='float')\n",
        "# dataset['Distress Barrier']=pd.Series([15669733148, 16622163564, 17776465778, 17833508474, 16877445036, 18517386840, 21442068690, 23291326752, 24542066485, 28766631090, 29199892732, 30006391296, 29813639417, 32344507489, 34364836658, 37469268824, 46353699857, 50017932700, 54655855964, 57011267289, 64287512856, 69763695000], dtype='float')\n",
        "# for t in range(1, end_year+1-start_year):\n",
        "#     dataset.iloc[t,3]=np.log(dataset.iloc[t,1] / dataset.iloc[t-1, 1]) #filling Log return\n",
        "\n",
        "# dataset['Log Return']= dataset['Log Return'].astype('float')\n",
        "# for i in range(2, end_year+1-start_year):\n",
        "#     returns=np.array(dataset.iloc[1:i+1, 3])\n",
        "#     yrly_vol=np.std(a=returns, dtype='float', ddof=1)*(np.sqrt(261))\n",
        "#     dataset.iloc[i, 4]=yrly_vol\n",
        "#     dataset.iloc[i, 5]=yrly_vol/np.sqrt(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "output=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Past RNPD', \"Def Probability\", 'Moody\\'s Ratings', 'Normalized Past RNPD'])\n",
        "# later add min max normalized Default Probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Log Return', 'Yearly Volatility', 'Quarter Volatility'])\n",
        "\n",
        "# start_year=2001\n",
        "# end_year=2022\n",
        "\n",
        "# dataset['Year']=np.arange(start_year, end_year+1)\n",
        "# dataset['Total Assets']= pd.Series([71753078142.00, 73535346705.00, 78235030416.00, 87355506463.00, 105912000000.00, 114571000000.00, 113550000000.00, 120751000000.00, 117451000000.00, 116042000000.00, 110884000000.00, 107309000000.00, 116030000000.00, 139673000000.00, 154796000000.00, 161894000000.00, 208396000000.00, 209056000000.00, 189460000000.00, 203829000000.00, 234233000000.00, 223807000000.00], dtype='float')\n",
        "# dataset['Distress Barrier']=pd.Series([15669733148, 16622163564, 17776465778, 17833508474, 16877445036, 18517386840, 21442068690, 23291326752, 24542066485, 28766631090, 29199892732, 30006391296, 29813639417, 32344507489, 34364836658, 37469268824, 46353699857, 50017932700, 54655855964, 57011267289, 64287512856, 69763695000], dtype='float')\n",
        "# for t in range(1, end_year+1-start_year):\n",
        "#     dataset.iloc[t,3]=np.log(dataset.iloc[t,1] / dataset.iloc[t-1, 1]) #filling Log return\n",
        "\n",
        "# dataset['Log Return']= dataset['Log Return'].astype('float')\n",
        "# for i in range(2, end_year+1-start_year):\n",
        "#     returns=np.array(dataset.iloc[1:i+1, 3])\n",
        "#     yrly_vol=np.std(a=returns, dtype='float', ddof=1)*(np.sqrt(261))\n",
        "#     dataset.iloc[i, 4]=yrly_vol\n",
        "#     dataset.iloc[i, 5]=yrly_vol/np.sqrt(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eVejKJ8kw3UR"
      },
      "outputs": [],
      "source": [
        "new_mat_og=pd.DataFrame([], columns=['Year', 'Total Assets', 'Distress Barrier', 'Volatility - Year', 'Volatility - Quarter', 'Quarter Number', 'N(d1)', 'd1', 'd2', 'N(-d2)', 'Moody\\'s Rating'])\n",
        "# we will have T+1 values per year, per simulation, qtr num onwards all unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "B7Z3vP4Qw2_L"
      },
      "outputs": [],
      "source": [
        "mu = 0.005   # drift\n",
        "r = 0.124     # risk-free rate\n",
        "T = 4\n",
        "M = 1         # maturity\n",
        "N_MC = 2500    # number of paths\n",
        "risk_lambda = 0.6\n",
        " # risk aversion parameter\n",
        "delta_t = M / T                # time interval\n",
        "gamma = np.exp(- r * delta_t)  # discount factor\n",
        "# Define the risk aversion parameter\n",
        "reg_param = 1e-3\n",
        "\n",
        "# To get meaninful results, one should have ncolloc >= p+1\n",
        "p = 4 # order of spline (as-is; 3: cubic, 4: B-spline?)\n",
        "ncolloc = 12\n",
        "\n",
        "num_t_steps = T + 1\n",
        "num_basis =  ncolloc\n",
        "\n",
        "year_avg=np.arange(0.0, 21.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S0dtfMK8xA8x"
      },
      "outputs": [],
      "source": [
        "# standard normal random numbers\n",
        "RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jL3tV8EFxA5X"
      },
      "outputs": [],
      "source": [
        "def terminal_payoff(ST, K):\n",
        "    # ST   final stock price    # K    strike\n",
        "    payoff = max(K - ST, 0)\n",
        "    return payoff\n",
        "\n",
        "\n",
        "# functions to compute optimal hedges\n",
        "def function_A_vec(t,delta_S_hat,data_mat_t):\n",
        "    # Compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n",
        "    X_mat = data_mat_t[t,:,:]\n",
        "    num_basis_funcs = X_mat.shape[1]\n",
        "    this_dS = delta_S_hat.loc[:,t].values\n",
        "    hat_dS2 = (this_dS**2).reshape(-1,1)\n",
        "    A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n",
        "    return A_mat\n",
        "\n",
        "\n",
        "def function_B_vec(t, Pi_hat, delta_S_hat, S, data_mat_t):\n",
        "    coef = 1.0/(2 * gamma * risk_lambda)\n",
        "    tmp =  Pi_hat.loc[:,t+1] * delta_S_hat.loc[:,t] + coef * (np.exp(mu*delta_t) - np.exp(r*delta_t))* S.loc[:,t]\n",
        "    X_mat = data_mat_t[t,:,:]  # matrix of dimension N_MC x num_basis\n",
        "    B = np.dot(X_mat.T, tmp)\n",
        "    return B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "euJCKshwxA1Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Year  2003 . Simulation 1 /20.\n",
            "\n",
            "Year  2004 . Simulation 2 /20.\n",
            "\n",
            "Year  2005 . Simulation 3 /20.\n",
            "\n",
            "Year  2006 . Simulation 4 /20.\n",
            "\n",
            "Year  2007 . Simulation 5 /20.\n",
            "\n",
            "Year  2008 . Simulation 6 /20.\n",
            "\n",
            "Year  2009 . Simulation 7 /20.\n",
            "\n",
            "Year  2010 . Simulation 8 /20.\n",
            "\n",
            "Year  2011 . Simulation 9 /20.\n",
            "\n",
            "Year  2012 . Simulation 10 /20.\n",
            "\n",
            "Year  2013 . Simulation 11 /20.\n",
            "\n",
            "Year  2014 . Simulation 12 /20.\n",
            "\n",
            "Year  2015 . Simulation 13 /20.\n",
            "\n",
            "Year  2016 . Simulation 14 /20.\n",
            "\n",
            "Year  2017 . Simulation 15 /20.\n",
            "\n",
            "Year  2018 . Simulation 16 /20.\n",
            "\n",
            "Year  2019 . Simulation 17 /20.\n",
            "\n",
            "Year  2020 . Simulation 18 /20.\n",
            "\n",
            "Year  2021 . Simulation 19 /20.\n",
            "\n",
            "Year  2022 . Simulation 20 /20.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in range(2, 22): #use this to mean from 2002 to 2022\n",
        "    count=i\n",
        "    curr_yr_avg=np.arange(0.0, T+2.0)\n",
        "\n",
        "    curr_year=i+2001\n",
        "\n",
        "    print(\"\\nYear \", curr_year, \". Simulation\", i-1,\"/20.\")\n",
        "\n",
        "    year=data.iloc[i, 0]\n",
        "    S0=data.iloc[i, 1]                 #initial stock price\n",
        "    S0=S0/1000000000\n",
        "    sigma=data.iloc[i, 3]              # yearly volatility\n",
        "    sigma_qtr=data.iloc[i, 4]          # quarterly volatility\n",
        "    K=data.iloc[i, 5]\n",
        "    K=K/1000000000\n",
        "    moody=data.iloc[i, 6]\n",
        "\n",
        "    # # standard normal random numbers\n",
        "    # RN = pd.DataFrame(np.random.randn(N_MC,T), index=range(1, N_MC+1), columns=range(1, T+1))\n",
        "\n",
        "    # print(\"year: \", year)\n",
        "    # print(\"S0: \", S0)\n",
        "    # print(\"sigma: \", sigma)\n",
        "    # print(\"sigma_qtr: \", sigma_qtr)\n",
        "    # print(\"K: \", K)\n",
        "\n",
        "    S = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    S.loc[:,0] = S0\n",
        "    # print(\"S\\n\", S.head)\n",
        "\n",
        "    for t in range(1, T+1):\n",
        "        S.loc[:,t] = S.loc[:,t-1] * np.exp((mu - 1/2 * sigma**2) * delta_t + sigma * np.sqrt(delta_t) * RN.loc[:,t])\n",
        "\n",
        "    # print(\"S\\n\", S.head)\n",
        "\n",
        "    delta_S = S.loc[:,1:T].values - np.exp(r * delta_t) * S.loc[:,0:T-1]\n",
        "    delta_S_hat = delta_S.apply(lambda x: x - np.mean(x), axis=0)\n",
        "\n",
        "    # state variable\n",
        "    X = - (mu - 1/2 * sigma**2) * np.arange(T+1) * delta_t + np.log(S.astype(float) / 1.0)  # delta_t here is due to their conventions\n",
        "    # print(\"X\\n\", X.head)\n",
        "\n",
        "    X_min = np.min(np.min(X))\n",
        "    X_max = np.max(np.max(X))\n",
        "\n",
        "    tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n",
        "\n",
        "    # k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n",
        "    k = splinelab.aptknt(tau, p)\n",
        "    # print(\"k: \", k)\n",
        "\n",
        "    # Spline basis of order p on knots k\n",
        "    basis = bspline.Bspline(k, p)\n",
        "    f = plt.figure()\n",
        "    # basis.plot()\n",
        "\n",
        "    # Make data matrices with feature values\n",
        "    data_mat_t = np.zeros((num_t_steps, N_MC, num_basis))\n",
        "\n",
        "    # fill it\n",
        "    for i in np.arange(num_t_steps):\n",
        "        x = X.values[:,i]\n",
        "        basis_arr=np.array([ basis(i) for i in x ])\n",
        "        data_mat_t[i,:,:] = basis_arr\n",
        "\n",
        "    # Compute optimal hedge and portfolio value\n",
        "    # portfolio value\n",
        "    Pi = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    Pi.iloc[:,-1] = S.iloc[:,-1].apply(lambda x: terminal_payoff(x, K))\n",
        "\n",
        "    Pi_hat = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "    Pi_hat.iloc[:,-1] = Pi.iloc[:,-1] - np.mean(Pi.iloc[:,-1])\n",
        "\n",
        "    # optimal hedge\n",
        "    a = pd.DataFrame([], index=range(1, N_MC+1), columns=range(T+1))\n",
        "\n",
        "    a.iloc[:,-1] = 0\n",
        "\n",
        "    for t in range(T-1, -1, -1):\n",
        "\n",
        "        A_mat = function_A_vec(t, delta_S_hat, data_mat_t)\n",
        "        B_vec = function_B_vec(t, Pi_hat, delta_S_hat, S, data_mat_t)\n",
        "\n",
        "        # Convert A_mat and B_vec to a NumPy array of floats\n",
        "        A_mat = np.array(A_mat, dtype=float)\n",
        "        B_vec = np.array(B_vec, dtype=float)\n",
        "\n",
        "        phi = np.dot(np.linalg.inv(A_mat), B_vec)\n",
        "        a.loc[:,t] = np.dot(data_mat_t[t,:,:],phi)\n",
        "        Pi.loc[:,t] = gamma * (Pi.loc[:,t+1] - a.loc[:,t] * delta_S.loc[:,t])\n",
        "        Pi_hat.loc[:,t] = Pi.loc[:,t] - np.mean(Pi.loc[:,t])\n",
        "\n",
        "    # print(\"a\\n\", a.head)\n",
        "    # print(\"Pi\\n\", Pi.head)\n",
        "\n",
        "    a_avg=a.mean()\n",
        "\n",
        "\n",
        "    # using Nd1 as is, 5 data points\n",
        "    Nd1_og=a_avg.astype(float)\n",
        "    # using zscore to get from Nd1 to d1\n",
        "    \n",
        "    d1_og = stats.zscore(Nd1_og)\n",
        "    # print(\"D1:\\n\",d1_og)e\n",
        "\n",
        "\n",
        "\n",
        "    # where T is the total number of timesteps\n",
        "    # the variable qtr is an iterator over the Timesteps, starting from O to T\n",
        "    # so it runs for a total of T+1 times (it T =2, qtr=[0,1,2])\n",
        "    for qtr in range(0,T+1): #in range(a,b), a in inclusive and b is exclusive\n",
        "        # print(qtr)\n",
        "        \n",
        "        this_Nd1_og=Nd1_og[qtr]\n",
        "        this_d1_og=d1_og[qtr]\n",
        "\n",
        "        d2_og=this_d1_og-(sigma_qtr*np.sqrt((T-qtr)/T))\n",
        "        # print(\"d2_og: \", d2_og)\n",
        "\n",
        "        Nd2_og=norm.cdf(-d2_og)\n",
        "        # print(\"N(-d2_og): \", Nd2_og)\n",
        "\n",
        "\n",
        "        # LCL = (S0*this_Nd1_og)-(K*Nposd2_og*np.exp(r*T))\n",
        "\n",
        "        new_row_og =[year, S0, K, sigma, sigma_qtr, qtr, Nd1_og[qtr], d1_og[qtr], d2_og, Nd2_og, moody]\n",
        "        # print(new_row_og)\n",
        "        new_mat_og.loc[len(new_mat_og)] = new_row_og\n",
        "        curr_yr_avg[qtr]=Nd2_og\n",
        "        # print(curr_yr_avg[qtr])\n",
        "    \n",
        "    sum=0\n",
        "    for i in range(0,T+1):\n",
        "        sum+=curr_yr_avg[i]\n",
        "    yr_avg=sum/T\n",
        "\n",
        "    # data = ['Year', 'Total Assets', 'Log Return', 'Yearly Volatility','Quarterly Volatility', 'Distress Barrier', 'Moody\\'s Ratings', 'Past RNPD', 'Normalized Past RNPD']\n",
        "    #output = 'Year', 'Total Assets', 'Distress Barrier', 'Past RNPD', \"Def Probability\", 'Moody\\'s Ratings', 'Normalized Past RNPD'])\n",
        "    new_output_row=[year, data.iloc[count, 1],  data.iloc[count, 5], data.iloc[count, 7], yr_avg, data.iloc[count, 6], data.iloc[count, 8]]\n",
        "    output.loc[len(output)] = new_output_row\n",
        "    # print(\"\\nloop over\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add min max norm of def probability\n",
        "\n",
        "# Calculate min and max of 'Def Probability'\n",
        "min_prob = output['Def Probability'].min()\n",
        "max_prob = output['Def Probability'].max()\n",
        "\n",
        "# Create a new column with normalized values\n",
        "output['Normalized Def Probability'] = (output['Def Probability'] - min_prob) / (max_prob - min_prob)\n",
        "\n",
        "us=output['Normalized Def Probability']\n",
        "moody=output['Moody\\'s Ratings']\n",
        "exesum=output['Normalized Past RNPD']\n",
        "output['EucDist - Moody vs Us'] = (np.sqrt((us-moody)**2))\n",
        "output['EucDist - Moody vs ExeSum'] = (np.sqrt((exesum-moody)**2))\n",
        "output['EucDist - Us vs ExeSum'] = (np.sqrt((us-exesum)**2))\n",
        "\n",
        "output[\"Compare RNPD\"] = [0.6305035, 0.63923975,\t0.61812033,\t0.65817712,\t0.71738401,\t0.78523653,\t0.79311,\t0.80536048,\t0.83774903,\t0.8355024,\t0.79626415,\t0.82442427,\t0.74055703,\t0.70127537,\t0.65587051,\t0.71405749,\t0.85471027,\t0.75278117,\t0.76817475,\t0.84146686]\n",
        "output[\"Compare Norm RNPD\"] = [0.05234022, 0.08926593, 0,         0.16930893,  0.41956002, 0.70635379, 0.73963276, 0.79141214, 0.92830955, 0.91881367, 0.75296448, 0.87198949, 0.51750594, 0.35147327, 0.15955953, 0.40549974, 1,         0.56917399, 0.63423838, 0.94402378]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bD2cbr_zxAyM"
      },
      "outputs": [],
      "source": [
        "# print(\"Original\\n\", new_mat_og)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "# Probability (quantile)\n",
        "prob = -0.03\n",
        "\n",
        "# Calculate the inverse CDF (95th percentile)\n",
        "value = stats.norm.ppf(prob, loc=mean, scale=std_dev)\n",
        "print(value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Year  Total Assets  Distress Barrier  Past RNPD  Def Probability  \\\n",
            "0   2003.0  7.823503e+10      1.777647e+10   0.805596         0.751441   \n",
            "1   2004.0  8.735551e+10      1.783351e+10   0.784603         0.735451   \n",
            "2   2005.0  1.060000e+11      1.687745e+10   0.719110         0.807782   \n",
            "3   2006.0  1.150000e+11      1.851739e+10   0.717527         0.763171   \n",
            "4   2007.0  1.140000e+11      2.144207e+10   0.752505         0.803417   \n",
            "5   2008.0  1.210000e+11      2.329133e+10   0.749984         0.773232   \n",
            "6   2009.0  1.170000e+11      2.454207e+10   0.767545         0.803496   \n",
            "7   2010.0  1.160000e+11      2.876663e+10   0.803313         0.809371   \n",
            "8   2011.0  1.110000e+11      2.919989e+10   0.816282         0.804928   \n",
            "9   2012.0  1.070000e+11      3.000639e+10   0.831299         0.803780   \n",
            "10  2013.0  1.160000e+11      2.981364e+10   0.813954         0.810932   \n",
            "11  2014.0  1.400000e+11      3.234451e+10   0.789567         0.749632   \n",
            "12  2015.0  1.550000e+11      3.436484e+10   0.787647         0.771753   \n",
            "13  2016.0  1.620000e+11      3.746927e+10   0.799126         0.799920   \n",
            "14  2017.0  2.080000e+11      4.635370e+10   0.790896         0.754919   \n",
            "15  2018.0  2.090000e+11      5.001793e+10   0.802758         0.748230   \n",
            "16  2019.0  1.890000e+11      5.465586e+10   0.833412         0.776832   \n",
            "17  2020.0  2.040000e+11      5.701127e+10   0.832693         0.765926   \n",
            "18  2021.0  2.340000e+11      6.428751e+10   0.825944         0.764450   \n",
            "19  2022.0  2.240000e+11      6.976370e+10   0.845625         0.767176   \n",
            "\n",
            "    Moody's Ratings  Normalized Past RNPD  Normalized Def Probability  \\\n",
            "0           0.33333              0.687513                    0.211839   \n",
            "1           1.00000              0.523627                    0.000000   \n",
            "2           0.33333              0.012356                    0.958263   \n",
            "3           0.00000              0.000000                    0.367243   \n",
            "4           0.00000              0.273051                    0.900432   \n",
            "5           0.33333              0.253376                    0.500534   \n",
            "6           0.66667              0.390467                    0.901486   \n",
            "7           0.33333              0.669691                    0.979315   \n",
            "8           0.33333              0.770933                    0.920448   \n",
            "9           1.00000              0.888165                    0.905240   \n",
            "10          0.33333              0.752762                    1.000000   \n",
            "11          1.00000              0.562384                    0.187872   \n",
            "12          0.66667              0.547397                    0.480944   \n",
            "13          0.66667              0.637003                    0.854103   \n",
            "14          0.66667              0.572760                    0.257915   \n",
            "15          0.66667              0.665356                    0.169293   \n",
            "16          0.66667              0.904659                    0.548231   \n",
            "17          0.66667              0.899046                    0.403742   \n",
            "18          0.66667              0.846362                    0.384189   \n",
            "19          1.00000              1.000000                    0.420300   \n",
            "\n",
            "    EucDist - Moody vs Us  EucDist - Moody vs ExeSum  EucDist - Us vs ExeSum  \\\n",
            "0                0.121491                   0.354183                0.475674   \n",
            "1                1.000000                   0.476373                0.523627   \n",
            "2                0.624933                   0.320974                0.945907   \n",
            "3                0.367243                   0.000000                0.367243   \n",
            "4                0.900432                   0.273051                0.627381   \n",
            "5                0.167204                   0.079954                0.247158   \n",
            "6                0.234816                   0.276203                0.511019   \n",
            "7                0.645985                   0.336361                0.309624   \n",
            "8                0.587118                   0.437603                0.149515   \n",
            "9                0.094760                   0.111835                0.017075   \n",
            "10               0.666670                   0.419432                0.247238   \n",
            "11               0.812128                   0.437616                0.374512   \n",
            "12               0.185726                   0.119273                0.066453   \n",
            "13               0.187433                   0.029667                0.217100   \n",
            "14               0.408755                   0.093910                0.314845   \n",
            "15               0.497377                   0.001314                0.496063   \n",
            "16               0.118439                   0.237989                0.356428   \n",
            "17               0.262928                   0.232376                0.495304   \n",
            "18               0.282481                   0.179692                0.462173   \n",
            "19               0.579700                   0.000000                0.579700   \n",
            "\n",
            "    Compare RNPD  Compare Norm RNPD  \n",
            "0       0.630503           0.052340  \n",
            "1       0.639240           0.089266  \n",
            "2       0.618120           0.000000  \n",
            "3       0.658177           0.169309  \n",
            "4       0.717384           0.419560  \n",
            "5       0.785237           0.706354  \n",
            "6       0.793110           0.739633  \n",
            "7       0.805360           0.791412  \n",
            "8       0.837749           0.928310  \n",
            "9       0.835502           0.918814  \n",
            "10      0.796264           0.752964  \n",
            "11      0.824424           0.871989  \n",
            "12      0.740557           0.517506  \n",
            "13      0.701275           0.351473  \n",
            "14      0.655871           0.159560  \n",
            "15      0.714057           0.405500  \n",
            "16      0.854710           1.000000  \n",
            "17      0.752781           0.569174  \n",
            "18      0.768175           0.634238  \n",
            "19      0.841467           0.944024  \n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
